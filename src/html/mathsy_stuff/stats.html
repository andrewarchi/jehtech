<!DOCTYPE html PUBLIC "-//W3C//DTD HTML 4.01//EN" "http://www.w3.org/TR/html4/strict.dtd">
<html>
<head>
	<meta http-equiv="Content-Type" content="text/html; charset=UTF-8"> <!-- HTML 4 -->
	<meta charset="UTF-8">                                              <!-- HTML 5 -->
	<title>Statistics notes</title>
	<!-- META_INSERT -->
	<link rel="stylesheet" href="../jeh-monolith.css" type="text/css" />
	<script src="../jeh-monolith.js"></script>
	<script type="text/x-mathjax-config">
		MathJax.Hub.Config({
			tex2jax: {
				inlineMath: [['$','$'], ['\\(','\\)']]
			},
			displayAlign: "left",
			displayIndent: "2em"
		});
	</script>
	<script type="text/javascript" src="https://cdn.mathjax.org/mathjax/latest/MathJax.js?config=TeX-AMS_HTML"></script>
	<style>
		ul li .MathJax {font-size: 3em;}
	</style>

	<script> 
	MathJax.Hub.Queue(function () {
		$("#dialog").dialog("close")
	});

	$(function(){
		$("#dialog").dialog({ autoOpen: false, resizable: false });
		$('#dialog').parent().css({position:"fixed"}).end().dialog('open');
	});
  </script>

  <style type="text/css">
      .noborder {
         border: 0px;
      }

      table.dataDefTable tr > td:first-child { 
         font-weight: bold;
      }

      table.allborders {
         border: 1px solid lightblue;
      }

      table.allborders tr td {
         border: 1px solid lightblue;
      }

      td.selcell {
         background: lightblue;
      }

      del {
         color: gray;
      }

   </style>
</head>

<body>
<div id="header">
   -- This is JEHTech --
</div>

<div id="dialog" title="Page still rendering...">
	<table style="width: 100%; margin: 0px; padding: 0px; border: 0px;">
		<tr>
			<td style="vertical-align:bottom !important; padding:0px; margin: 0px; width:60px;">
				<img src="../images/jeh-tech/loading_animation.gif" style="width:50px; height:50px;">
			</td>
			<td>
				MathJax is busy rendering this page. Dialog will auto-close when ready. Please wait...
			</td>
		</tr>
	</table>
</div>

<div id="sidebar">
   <h1 class="title">Links...</h1>
   <div id="includedContent"></div>
</div>

<div id="content">
   <h1 class="title">Statistics Notes</h1>
   <p>
   </p>
   <h2>Page Contents</h2>
   <div id="page_contents">
   </div>

<h2>The Basics of Discrete Probability Distributions</h2>
<div>
   <h3>Some Terminology</h3>
   <h4>Variables...</h4>
   <table class="dataDefTable noborder">
      <tr><td>Categorical Variable</td>
          <td>Discrete variable which can be one of a set of such as the anwer
              to a YES/NO question: the variable can be either YES or NO. Or the
              answer to a quality question where the choices are good, ambivalent
              or bad, for example.
          </td>
      </tr>
      <tr><td>Numerical Variable</td>
          <td>Has a value from a set of numbers. That set can be continuous,
              like the set of real numbers, or discrete like the set of
              integers.
          </td>
      <tr>
         <tr><td>Random Variable</td>
            <td>The numerical outcome of a random experiment. <em>Discrete</em> if it 
               can take on more than a countable number of values. <em>Continuous </em>
                 if it can take any value over an uncountable range.
             </td>
      </tr>
      <tr><td>Qualitative Data</td>
          <td>Data where there is no measurable difference (in a quantitative 
              sense) between two values (that makes sense). For example, the colour of a car.
              The car can be &quot;nice&quot; or &quot;sporty&quot;, but we 
              can't define the the difference in terms of a number like 4.83,
              for example.
           </td>
      </tr>
      <tr><td>Quantitative Data</td>
          <td>Data is numerical and the difference between data is a
              well defined notion. For example, if car A goes 33 MPG and
              care B does, 40 MPG, then we can say the difference is 7MPG.
          </td>
      </tr>
      <tr><td>Ordinal Data</td>
          <td>The value of the data has an order with respect to other
              possible values.
          </td>
      </tr>
   </table>

   <h4>Populations and samples...</h4>
   <p>It is always worth keeping in mind that <b>probability is a measure
      describing the likelihood of an event from the <u>population</u></b>. 
      It is <em>not</em> &quot;in&quot; the data set (or sample)
      obtained... a sample is user to <em>infer</em> a probability about a
      population parameter.
   </p>
   <table class="dataDefTable noborder">
      <tr><td>Population</td>
          <td>The complete set of items of interest.
             Size is very large, denoted <i>N</i>, possibly infinite. 
             Population is the entire pool from which a statistical sample is draw.
          </td>
      </tr>
      <tr><td>Sample</td>
          <td>An observed subset of the population. Size denoted <i>n</i>.
          </td>
      </tr>
      <tr><td>Random Sampling</td>
          <td>Select <i>n</i> objects from population such that each object
              is equally likely to be chosen. Selecting 1 object does not
              influence the selection of the next. Selection is utterly
              by chance.
          </td>
      </tr>
      <tr><td>Parameter</td>
          <td>Numeric measure describing a characteristic of the 
              <i>population</i>.
          </td>
      </tr>
      <tr><td>Statistic</td>
         <td>Numeric measure describing a characteristic of the <i>sample</i>.
             Statistics are used to <em>infer</em> population parameters.
         </td>
      </tr>
      <tr><td>Inference</td>
          <td>The process of making conclusions about the propulation from noisy
              data that was drawn from it. Involves formulating conclusions using data 
              and quantifying the uncertainty associated with those conclusions.
          </td>
      </tr>
   </table>

   <h4>Experiments...</h4>
   <table class="dataDefTable noborder">
      <tr><td>Random Experiment</td>
          <td>Action(s) that can lead to $\ge$2 outcomes where one cannot be sure,
              before performing the experiment, what the outcome would be.
          </td>
      </tr>
      <tr><td>Basic Outcomes</td>
          <td>A possible outcome from a random experiment. For example, flipping
              a coin has two basic outcomes: heads or tails.
          </td>
      </tr>
      <tr><td>Sample Space</td>
          <td>The set of all possible basic outcomes (exhaustively) from a random experiment.
              Note that this implies that the total number of possible outcomes is, or can be, known.
          </td>
      </tr>
      <tr><td>Event</td>
          <td>A subset of basic outcomes from a sample space. For example,
              a dice roll has 6 basic outcomes, 1 through 6. The sample space
              is therefore the set <tt>{1, 2, 3, 4, 5, 6}</tt>. The event
              &quot;roll a 2 or 3&quot; is the set <tt>{2, 3}</tt>.
           </td>
      </tr>
   </table>

   <h4>Distributions...</h4>
   <table class="dataDefTable noborder">
      <tr><td>Probability Mass Function (PMF)</td>
          <td>When evaluation a <i>n</i> function gives the probability that
              a random variable takes the value <i>n</i>. Only associated
              with <em>discrete</em> random variables. Also note that the
              function <b>descibes the population</b>.
          </td>
          <tr><td>Probability Density Function (PDF)</td>
              <td>Only associated with <em>continuous</em> random variables.
                  The area between two limits corresponds to the probabilty that the random 
                  variable lies within those limits. A single point has 
                  a zero probability. Also note that the
                  function <b>descibes the population</b>.
              </td>
          </tr>
          <tr><td>Cumulative Distribution Function (CDF)</td>
              <td>Returns the probability that $X \le x$.
              </td>
          </tr>
          <tr><td>Quantile</td>
              <td>The $\alpha^{th}$ quantile of a distribution, $F$, is the point 
                  $x_\alpha$ such that $F(x_\alpha) = \alpha$.
              </td>
          </tr>
   </table>

   <p></p>

   <h3>Population And Sample <i>Space</i></h3>
   <p>
      We have said that the population is the complete set of items of interest.
   </p>
   <p>
      We have said that the sample space is the set of all possible outcomes (exhaustively) from a random experiment.
   </p>
   <p>
      So I wondered this. Take a dice roll. The population is the complete set of possible items <tt>{1, 2, 3, 4, 5, 6}</tt>.
      The sample space is the set of all possible outcomes, also <tt>{1, 2, 3, 4, 5, 6}</tt>. So here sample space and 
      population appear to be the same thing, so when are they not and what are the distinguishing factors between the two??
   </p>
   <p>
      The <a href="https://en.wikipedia.org/wiki/Sample_space" target="_blank">WikiPedia page on sample spaces</a> caused the penny to drop for me:
   </p>
   <p>
      <q>...For many experiments, there may be more than one plausible sample space available, depending on what result is of interest to the experimenter. For example, when drawing a card from a standard deck of fifty-two playing cards, one possibility for the sample space could be the various ranks (Ace through King), while another could be the suits (clubs, diamonds, hearts, or spades)...</q>
   </p>
   <p>
      Ah ha! So my population is the set of all cards <tt>{1_heart, 2_heart, ..., 
      ace_heart, 1_club, ...}</tt> but the sample space may be, if we are looking 
      for the suits, just <tt>{heart, club, diamond, spade}</tt>. So the population and
      sample space are different here. In this case the sample space consists of cards 
      seperated into groups of suites. I.e. the popultation has been split into 4 
      groups because there are 4 events of interest. These events cover the sample space.
   </p>
   <p>
      In summary the population is the set of items I'm looking at. The sample space may or may not be 
      the population... that depends on what question about the population is being asked and how
      the items in the population are grouped per event. 
   </p>

   <a name="classicprob"><h3>Classic Probability</h3></a>
   <p>
   In classic probability we assume <em>all the basic outcomes are equally likely</em>
      and therefore the probability of an event, A, is the number of basic
      outcomes associated with A divided by the total number of possible outcomes:

      $$
      \begin{align}
         P(A) &= \frac{number\ of\ outcomes\ relevant\ to\ event\ A}{total\ number\ of\ outcomes} \\
              &= \frac{N_A}{N}
      \end{align}
      $$

      Each basic output is <em>equally likely</em>. And, note, here we are talking
      about outcomes in the <em>population</em>.
   </p>
   <p>
      An example of the use of classical probability might be a simple bag of
      marbles. There are 3 blue marbles, 2 red, and 1 yellow. 
   </p>
   <p>
      If my experiment is to draw out 1 marble then the set of basic outcomes
      is 
      <tt>{B<sub>1</sub>, B<sub>2</sub>, B<sub>3</sub>, 
           R<sub>1</sub>, R<sub>2</sub>, Y<sub>1</sub>}</tt>. 
      This is also the population!
      Also, note that the sample space isn't
      <tt>{B, R, Y}</tt> because we can differentiate between similar coloured
      marbles and there is a certain quanity of each.
   </p>
   <p>
      So, what is the probability of picking out a red. Well, here $N = 6$ and
      $N_A = 2$ because there are 2 red marbles in the sack. Therefore the
      probability is:
      
      $$
         P(red) = \frac{2}{6} = \frac{1}{3}
      $$
   </p>
   <a name="stats_eg_of_perms_and_combs">
   <p>
      What if my experiment is to draw 2 marbles from the sack? Now the set
      of all possible basic outcomes, if the order of draw was important
      would be a 
      <a href="math_revision.html#combinations_permutations">permutation</a>.
      This means that if I draw, for example, R<sub>1</sub> then B<sub>2</sub>,
      I would consider it to be a distinctly different outcomes to drawing
      B<sub>2</sub> then R<sub>1</sub>. That means my population is:
   </p>
   <table class="allborders">
        <tr><td>Selection 1</td>    <td>Selection 2</td>        <td>Selection 1</td>    <td>Selection 2</td></tr>
        <tr><td>B<sub>1</sub></td>  <td>B<sub>2</sub></td>      <td>B<sub>2</sub></td>  <td>B<sub>1</sub></td></tr>
        <tr><td>B<sub>1</sub></td>  <td>B<sub>3</sub></td>      <td>B<sub>2</sub></td>  <td>B<sub>3</sub></td></tr>
        <tr><td>B<sub>1</sub></td>  <td>R<sub>1</sub></td>      <td>B<sub>2</sub></td>  <td>R<sub>1</sub></td></tr>
        <tr><td>B<sub>1</sub></td>  <td>R<sub>2</sub></td>      <td>B<sub>2</sub></td>  <td>R<sub>2</sub></td></tr>
        <tr><td>B<sub>1</sub></td>  <td>Y<sub>1</sub></td>      <td>B<sub>2</sub></td>  <td>Y<sub>1</sub></td></tr>


        <tr><td>B<sub>3</sub></td>  <td>B<sub>1</sub></td>      <td></td><td></td></tr>
        <tr><td>B<sub>3</sub></td>  <td>B<sub>2</sub></td>      <td></td><td></td></tr>
        <tr><td>B<sub>3</sub></td>  <td>R<sub>1</sub></td>      <td></td><td></td></tr>
        <tr><td>B<sub>3</sub></td>  <td>R<sub>2</sub></td>      <td></td><td></td></tr>
        <tr><td>B<sub>3</sub></td>  <td>Y<sub>1</sub></td>      <td></td><td></td></tr>

        <tr><td>R<sub>1</sub></td>  <td>R<sub>2</sub></td>      <td>R<sub>2</sub></td>  <td>R<sub>1</sub></td></tr>
        <tr><td>R<sub>1</sub></td>  <td>B<sub>1</sub></td>      <td>R<sub>2</sub></td>  <td>B<sub>1</sub></td></tr>
        <tr><td>R<sub>1</sub></td>  <td>B<sub>2</sub></td>      <td>R<sub>2</sub></td>  <td>B<sub>2</sub></td></tr>
        <tr><td>R<sub>1</sub></td>  <td>B<sub>3</sub></td>      <td>R<sub>2</sub></td>  <td>B<sub>3</sub></td></tr>
        <tr><td>R<sub>1</sub></td>  <td>Y<sub>1</sub></td>      <td>R<sub>2</sub></td>  <td>Y<sub>1</sub></td></tr>

        <tr><td>Y<sub>1</sub></td>  <td>B<sub>1</sub></td>      <td></td><td></td></tr>
        <tr><td>Y<sub>1</sub></td>  <td>B<sub>2</sub></td>      <td></td><td></td></tr>
        <tr><td>Y<sub>1</sub></td>  <td>B<sub>3</sub></td>      <td></td><td></td></tr>
        <tr><td>Y<sub>1</sub></td>  <td>R<sub>1</sub></td>      <td></td><td></td></tr>
        <tr><td>Y<sub>1</sub></td>  <td>R<sub>2</sub></td>      <td></td><td></td></tr>
   </table>
   <p>
      Which is a real nightmare to compute by trying to figure out all the permutations by
      hand, and imagine, this is only a small set! Maths to the rescue...
   </p>
   <p>
      $$
         \begin{align}
            Permutations &= {_{n}P_r} = \frac{n!}{(n-r)!} \\
                         &= {_{6}P_2} = \frac{6!}{(6-2)!} \\
                         &= \frac{6 \times 5 \times 4 \times 3 \times 2 }{4 \times 3 \times 2} \\
                         &= 6 \times 5 \\
                         &= 30
         \end{align}
      $$
   </p>
   <p>
      And that is how many permutations we have in the above table (thankfully!).
   </p>
   <p>
   So, if my question is what is the probability of drawing a red <em>then</em> a yellow
      marble, my event space is the set 
      <tt>{R<sub>1</sub>Y<sub>1</sub>, R<sub>2</sub>Y<sub>1</sub>}</tt>.<br/>
      Thus, if we say event A is &quot;draw a red then a yellow marble&quot;,

      $$
         P(A) =  \frac{N_A}{N} = \frac{2}{30} = \frac{1}{15}
      $$
   </p>

   <p>
      What if we don't care about the order. What is the probability of 
      drawing a red <em>and</em> a yellow? I.e. we consider RY and YR to be
      the same event...
   </p>
   <p>
      Our event space therefore becomes:
      <br/>
      <tt>{R<sub>1</sub>Y<sub>1</sub>, R<sub>2</sub>Y<sub>1</sub>
           Y<sub>1</sub>R<sub>1</sub>, Y<sub>1</sub>R<sub>2</sub>}</tt>.
   </p>
   <p>
      Thus, if we say event A is &quot;draw a red and a yellow marble&quot;,

      $$
         P(A) =  \frac{N_A}{N} = \frac{4}{30} = \frac{2}{15}
      $$
   </p>
   
   <p>
      We are essentially now
      dealing with <a href="math_revision.html#combinations_permutations">combinations</a>.
   </p>
   <p>
      Therefore in the above table, where we see things like...
   </p> 
   <table class="allborders">
      <tr><td>Selection 1</td>    <td>Selection 2</td></tr>
      <tr><td>B<sub>1</sub></td>  <td>B<sub>2</sub></td></tr>
      <tr><td>B<sub>2</sub></td>  <td>B<sub>1</sub></td></tr>
   </table>
   <p>
      ...we can delete one of the rows. The set of all basic outcomes therefore
      becomes:
   </p>
   <table class="allborders">
        <tr><td>Selection 1</td>    <td>Selection 2</td>        <td>Selection 1</td>    <td>Selection 2</td></tr>
        <tr><td>B<sub>1</sub></td>  <td>B<sub>2</sub></td>      <td><del>B<sub>2</sub></del></td>  <td><del>B<sub>1</sub></del></td></tr>
        <tr><td>B<sub>1</sub></td>  <td>B<sub>3</sub></td>      <td>B<sub>2</sub></td>  <td>B<sub>3</sub></td></tr>
        <tr><td>B<sub>1</sub></td>  <td>R<sub>1</sub></td>      <td>B<sub>2</sub></td>  <td>R<sub>1</sub></td></tr>
        <tr><td>B<sub>1</sub></td>  <td>R<sub>2</sub></td>      <td>B<sub>2</sub></td>  <td>R<sub>2</sub></td></tr>
        <tr><td>B<sub>1</sub></td>  <td>Y<sub>1</sub></td>      <td>B<sub>2</sub></td>  <td>Y<sub>1</sub></td></tr>


        <tr><td><del>B<sub>3</sub></del></td>  <td><del>B<sub>1</sub></del></td>      <td></td><td></td></tr>
        <tr><td><del>B<sub>3</sub></del></td>  <td><del>B<sub>2</sub></del></td>      <td></td><td></td></tr>
        <tr><td>B<sub>3</sub></td>  <td>R<sub>1</sub></td>      <td></td><td></td></tr>
        <tr><td>B<sub>3</sub></td>  <td>R<sub>2</sub></td>      <td></td><td></td></tr>
        <tr><td>B<sub>3</sub></td>  <td>Y<sub>1</sub></td>      <td></td><td></td></tr>

        <tr><td>R<sub>1</sub></td>  <td>R<sub>2</sub></td>      <td><del>R<sub>2</sub></del></td>  <td><del>R<sub>1</sub></td></del></tr>
        <tr><td><del>R<sub>1</sub></del></td>  <td><del>B<sub>1</sub></del></td>      <td><del>R<sub>2</sub></del></td>  <td><del>B<sub>1</sub></del></td></tr>
        <tr><td><del>R<sub>1</sub></del></td>  <td><del>B<sub>2</sub></del></td>      <td><del>R<sub>2</sub></del></td>  <td><del>B<sub>2</sub></td></del></tr>
        <tr><td><del>R<sub>1</sub></del></td>  <td><del>B<sub>3</sub></del></td>      <td><del>R<sub>2</sub></del></td>  <td><del>B<sub>3</sub></del></td></tr>
        <tr><td>R<sub>1</sub></td>  <td>Y<sub>1</sub></td>      <td>R<sub>2</sub></td>  <td>Y<sub>1</sub></td></tr>

        <tr><td><del>Y<sub>1</sub></del></td>  <td><del>B<sub>1</sub></del></td>      <td></td><td></td></tr>
        <tr><td><del>Y<sub>1</sub></del></td>  <td><del>B<sub>2</sub></del></td>      <td></td><td></td></tr>
        <tr><td><del>Y<sub>1</sub></del></td>  <td><del>B<sub>3</sub></del></td>      <td></td><td></td></tr>
        <tr><td><del>Y<sub>1</sub></del></td>  <td><del>R<sub>1</sub></del></td>      <td></td><td></td></tr>
        <tr><td><del>Y<sub>1</sub></del></td>  <td><del>R<sub>2</sub></del></td>      <td></td><td></td></tr>
   </table>
   <p>Again a nightmare to figure out by hand, so maths to the resuce...
   </p>
    <p>
      $$
         \begin{align}
            Combinations &= {_{n}P_r} = \frac{n!}{r!(n-r)!} \\
                         &= {_{6}P_2} = \frac{6!}{2!(6-2)!} \\
                         &= \frac{6 \times 5 \times 4 \times 3 \times 2 }{4 \times 3 \times 2 \times 2} \\
                         &= \frac{6 \times 5}{2} \\
                         &= 15
         \end{align}
      $$
   </p>
   <p>
      And, again, that is how many selections (not included the ones we've deleted using a strikethrough font) 
      we have in the above table (thankfully!).
   </p>
   <p>
      So, now we can't ask about drawing a red <em>then</em> a yellow
      marble anymore as order doesn't matter. We can ask about drawing a red
      <em>and</em> a yellow though.
      My event space is now the set <br/>
      <tt>{R<sub>1</sub>Y<sub>1</sub>, R<sub>2</sub>Y<sub>1</sub>
         <del>Y<sub>1</sub>R<sub>1</sub>, Y<sub>1</sub>R<sub>2</sub></del>}</tt><br/>
      because I not longer care about order-of-draw...
      
      Thus, if we say event A is &quot;draw a red and a yellow marble&quot;,
      $$
         P(A) =  \frac{N_A}{N} = \frac{2}{15}
      $$
   </p>

   <h3>Relative Frequency Probability</h3>
   <p>
      Here the probability probability of an 
      event occuring is is the limit of the proportion of times an event occurs in
      a large number of trials. Why the limit? Well, the limit would mean we tested
      the entire popultation. Usually, however, we just pick a very large <i>n</i>
      and <em>infer</em> the popultation statistic from that.
      $$
      P(event) = \lim \limits_{n \to \infty} \frac{n_A}{n}
      $$

      Where $n_a$ is the number of exerimental outcomes relevant to event A,
      and $n$ is the total number of outcomes.
   </p>

   <p>
      So, for example, if we flip a coin 1000 times there are 1000 total number of outcomes.
      If we observed 490 heads and 510 tails we would have...
      $$\begin{align}
      P(head) &= \frac{490}{1000} &= 0.49  \\

      P(tail) &= \frac{510}{1000} &= 0.51
      \end{align}$$
   </p>
   <p>
      If the coin was entirely fair then we would expect an equal probability
      of getting a head or a tail. Frequentist theory states that as the sample 
      size gets bigger, i.e., as we do more and more coin flips, if the coin
      is fair the probabilities will tend towards 50%. So if we did 1,000,000
      samples, for example, we might expect...

      $$\begin{align}
      P(head) &= \frac{500100}{1000000} &= 0.5001  \\

      P(tail) &= \frac{499900}{1000000} &= 0.4999
      \end{align}$$

      So... more samples, the closer our probability estimate is to the <em>real</em>
      probabilities for getting a head or tail. The limit of the probabilities as
      the sample size tends to infinitely will be exactly 50%. The &quot;<em>real</em>&quot;
      is the probability from the <em>population</em>. Anything less is a <em>sample</em>
      of the population.
   </p>

   <p>
      As <i>n</i> tends to infinity, we can say that <i>n</i> tends towards
      the popultation size, and then at this point you will arrive back at
      the formula for conditional probability you saw in the previous section
   </p>


   <h3>Event A <u>OR</u> Event B</h3>
   <table style="border:0px">
      <tr><td>$A$ and $B$ are <em>independent</em>:</td><td>$P(A \cup B) = P(A) + P(B)$</td></tr>
      <tr><td>$A$ and $B$ are <em>not</em> independent:</td><td>$P(A \cup B) = P(A) + P(B) - P(A \cup B)$</td></tr>
   </table>
   <p>
      We can visualise this as follows, using a Venn diagram...
   </p>
   <p>
      <a name="two_independent_venn">
         <img src="##IMG_DIR##/Prob_A_and_B_independent.png" alt="Venn diagram of probability for A and B and A or B when events are independent">
      </a>
   </p>
   <p>
      If two events are independent then we can see that none of the basic outcomes from either event can occur for the other.
      Therefore, using either classical or relative-frequency probability we can see that $P(A \cup B) = P(A) + P(B)$.
   </p>
   <p>
      <a name="two_dependent_venn">
         <img src="##IMG_DIR##/Prob_A_and_B_dependent.png" alt="Venn diagram of probability for A and B and A or B when events are dependent">
      </a>
   </p>
   <p>
      Now the two events are related. They are no longer independent because some of the basic
      outcomes from one event are also basic outcomes of the other. Thus we can see that
      if we sum the probabilities for the basic outcomes for each, we will count the shared
      basic outcomes twice!
   </p>
   <p>
      If that's not clear, think of it this way...
   </p>
   <p>
      <img src="##IMG_DIR##/Prob_A_and_B_double_count.png" alt="">
   </p>

   <h3>Event A <u>AND</u> Event B</h3>
   <p>
      We just talked about independence, but how do we know if an event A, is
      independent of another event, B? The answer is that <b>two events are
      indpendent if $P(A \cap B) = P(A)P(B)$</b>.
   </p>
   <p>
      Why is this? Let's think of this from the relative frequency point of
      view. We know that $P(A) = n_a/n$ and that $P(B) = n_b/n$ for the sample
      and as n tends to infinity for the population. 
    </p>
    <p>
      For every basic outcome in the set A, we can
      pick an outcome from the set B, so the count of the combination of all possible
      outcomes from both sets must be $n_a \times n_b$. But this only makes
      sense if the events are mutually exlusive (i.e., don't overlap).

      $$
         P(A)P(B) = \frac{n_a \times n_b}{n}
      $$

      (See the previous <a href="#two_independent_venn">figure of a Venn Diagram for two independent events</a>
      to make this more clear in your mind).
   </p>
   <p>
      So, what if the events are <em>not</em> independent? Then it is no longer true
      that the count of combination of all possible outcomes is $n_a \times n_b$.
      Why is this? This is because the events that can be in both A and B
      now represent a much smaller portion of sample space. The probability 
      that A and B occur is now the solid-gray shaded area of the 
      <a href="#two_dependent_venn">Venn diagram for dependent events</a>.
   </p>
   <p>
      Think if it this way. For A and B to both occur, at least one must have
      occurred, so now the only possible choices from the other event are
      in the overlapping region, not in the entire event space. Keep reading 
      the next section on condition probability to find out more
      about why this is an indicator of independence.
   </p>
   <p>
      <table class="allborders">
      <tr><td></td>              <td>$A$</td>                  <td>$\overline A$</td>                  <td></td></tr>
      <tr><td>$B$</td>           <td>$A \cap B$</td>           <td>$\overline A \cap B$</td>           <td>$\Sigma = P(B)$</td></tr>
      <tr><td>$\overline B$</td> <td>$A \cap \overline B$</td> <td>$\overline A \cap \overline B$</td> <td>$\Sigma = P(\overline B)$</td></tr>             
      <tr><td></td>              <td>$\Sigma = P(A)$</td>      <td>$\Sigma = P(\overline A)$</td>      <td>$\Sigma = 1$</td></tr>             
      </table>
   </p>

   <a href="conditional_prob"><h3>Event A <u>GIVEN</u> Event B</h3></a>
   <p>
      If I live with my partner it seems intuitively correct to say that the
      probability of myself getting a cold would be heightend if my partner
      caught a cold. Thus there is an intutive difference between the 
      probability I will catch a cold and the probability that I will catch
      a cold, given my partner has already caught one.
   </p>
   <p>
      This is the idea behind <em>conditioning</em>: conditioning on what
      you know can change the probability of an outcome with no apriori
      knowledge of the data.
   </p>
   <p>
      <img src="##IMG_DIR##/Prob_Conditional.png" alt="Conditional probability venn diagram">
   </p>
   <p>
      Lets look at a really simple example. I roll a dice... what is the probability
      that I roll a 3. We assume a fair dice, so the answer is easy: 1/6.
      The set all of basic outcomes was <tt>{1, 2, 3, 4, 5, 6}</tt> (the sample space) and only
      one outcome was relevant for our event... so 1/6.
   </p>
   <p>
      Now lets say I have rolled the dice and I have been informed that the
      result was an odd number. With this knowledge, what is the probability that
      I rolled a 3? The set of basic outcomes is now narrowed to <tt>{1, 3, 5}</tt>
      and so the probability is now 1/3!
   </p>
   <p>
      The probability of event A given that event B has occurred is denoted
      $P(A | B)$ and is defined as follows:

      $$
         P(A | B) = \frac{P(A \cap B)}{P(B)}, when\ P(B) \ne 0
      $$
   </p>
   <p>
      This makes intuitive sense. If B has occurred then the number of outcomes
      to &quot;choose&quot; from is represented by the circle for B in the 
      Venn diagram below. The number of of outcomes that can belong to event
      A, given that we know event B has occurred, is the intersection.
      Therefore, our sample space is really now all the outcomes for event B,
      so $n \equiv n_b$, and the event of interest for A is now restricted to
      $n_{a \cap b}$. So we get...

      $$
      P(A | B) = \frac{n_{a \cap b}}{n_b} = \frac{\frac{n_{a \cap b}}{n}}{\frac{n_b}{n}} = \frac{P(A \cap B)}{P(B)}
      $$
   </p>
   <p>
      If A and B are independent then clearly, because $n_{a \cap b} = 0$, $P(A | B) = 0$.
   </p>
   <p>
      We can re-arrange the above to get another formula for $P(A \cap B)$...

      $$
         P(A \cap B) = P(A | B)P(B)
      $$
   </p>
   <p>
      And now we can see why, if two events are independent that $P(A \cap B) = P(A)P(B)$...
      because when A and B are independent $P(A | B) \equiv P(A)$!. And when they are
      dependent that equality is not true.
   </p>
   <p>
      A small bit on terminology... $P(A)$ is ofter called the <b>prior</b> probability and
      $P(A | B)$ the <b>posterior</b> probability.
   </p>
   <p>
      <q>...A posterior probability is the probability of assigning observations 
         to groups given the data. A prior probability is the probability that 
         an observation will fall into a group before you collect the data. For 
         example, if you are classifying the buyers of a specific car, you might 
         already know that 60% of purchasers are male and 40% are female. If you 
         know or can estimate these probabilities, a discriminant analysis can 
         use these prior probabilities in calculating the posterior probabilities.
      </q><br/>
      <i>-- <a href="http://support.minitab.com/en-us/minitab/17/topic-library/modeling-statistics/multivariate/discriminant-analysis/what-are-posterior-and-prior-probabilities/" target="_blank">Minitab support</a></i>
   </p>
   <p>
      From the definitions so far we can also see that

      $$
         P(A | B) + P(\overline A | B) = 1 
      $$

      But that the following does not (necessarily) equal 1,

      $$
         P(A | B) + P(A | \overline B) \ne 1
      $$
   </p>

   <p>
      Why is this important? Let's look at a little example. Say we have a
      clinical test for Influenza. Imagine that we know that for a patient the
      probability that they have or do not have Influenza.

      $$
      P(Flu) = 0.05 \implies P(\overline{Flu}) = 0.95
      $$
   </p>
   <p>
      Any clinical test is normally judged by it's sensitivity and specificity.
      Sensitivity is the probability that the test reports infection if the
      patient has Influenza (i.e true positives). 
      Sepcificity is the probability that the test
      reports the all-clear if the patient does not have Influenza (i.e., true
      negatives).
   </p>
   <p>
      Let's say the test has the following sensitivity and specificity respectively:

      $$
      \begin{align}
      P(+ | Flu) &= 0.9  \\
      P(- | \overline{Flu}) &= 0.9
      \end{align}
      $$

      Because we know $ P(A | B) + P(\overline A | B) = 1$, we can say:

      $$
      \begin{align}
      P(- | Flu) &= 0.1 \\
      P(+ | \overline{Flu}) &= 0.1
      \end{align}
      $$

      But a clinitian wants to know the probabilities the other way around. The
      clinician will ask &quot;if my patient has the flu, what is the probability
      that the test will call a positive?&quot; I.e., the clinician wants to 
      know $P(Flu | +)$
   </p>
   <p>
      We can use the conditional probability formula to work this out...

      $$
      \begin{align}
         P(Flu | +) &= \frac{P(Flu \cap +)}{P(+)} \\
                    &= \frac{P(+ \cap Flu)}{P(+)}
      \end{align}
      $$

      We can find out $P(+ \cap Flu)$ because $P(+ \cap Flu) = P(+ | Flu)P(Flu)$,
      which are quantities we already know, so we get...

      $$
      \begin {align}
         P(+ \cap Flu) &= P(+ | Flu)P(Flu) \\
                       &= 0.9 \times 0.05 \\
                       &= 0.045
      \end{align}
      $$

      We're close, but what is the value for $P(+)$? The answer is
      $P(+) = P(+ \cap Flu) + P(+ \cap \overline{Flu})$:

      $$
      \begin{align}
      P(+) &= P(+ \cap Flu) + P(+ \cap \overline{Flu}) \\
              &= 0.045 + ? 
      \end{align}
      $$

      We still need to know $P(+ \cap \overline{Flu})$. We know that
      $P(+ \cap \overline{Flu}) = P(+ | \overline{Flu})P(\overline{Flu})$, and we know
      these quantities already, so:

      $$  P(+ \cap \overline{Flu}) = 0.1 * 0.95 = 0.095
      $$

      Therefore,

      $$P(+) = 0.045 + 0.095 = 0.14$$

      Which means we can work out the entire thing (to 4dp):

      $$ P(Flu|+) = \frac{0.045}{0.14} = 0.3214
      $$
   </p>

   


   <h3>Sensitivity v.s. Specificity</h3>
   <p>
      In clinical tests, the user often wants to know about the sensitivity of a
      test. I.e., if the patient does have the disease being tested for, what
      is the probability that that the test will call a positive results. Obviously,
      we would like this to be as close to 100% as possible!
   </p>
   <p>
      The clinician would also like to know, if the patient did not have the
      disease, what is the probability that the test calls a negative. Again,
      we would like this to be as close to 100% as possible!
   </p>
   <p>
      To summarise: sensitivity is the probability of a true positive, and
      specificity is the probability of a true negative.
   </p>
   <p>
      Sensitivity: $P(+ | D)$ <br/>
      Specificity: $P(- | \overline D)$
   </p>

   <h3>Compliments</h3>
   <p>
      $$
         P(A \cup \overline A) = P(A) + P(\overline A) = 1\\
         P(\overline A) = 1 - P(A)
      $$
   </p>

   <h3>Bayes' Theorem</h3>
   <p>
      Recall the multiplication rule:

      $$
         P(A \cap B) = P(A | B)P(A) = P(B | A)P(A)
      $$

      By re-arranging the above we can arrive at the following:

      $$
         P(A | B) = \frac{P(B | A)P(A)}{P(B)},\ \ \ P(B | A) = \frac{P(A | B)P(B)}{P(A)} 
      $$
   </p>
   <p>
      Because we know that $P(B) = P(A \cap B) + P(\overline A \cap B)$ we 
      could also write:
  
      $$
         P(A | B) = \frac{P(B | A)P(A)}{P(A \cap B) + P(\overline A \cap B)} 
      $$
 
      An because we know $P(A \cap B) = P(B | A)P(A)$ and  $P(\overline A \cap B) = P(\overline B | A)P(A)$,
      we can re-write this as:

      $$
         P(A | B) = \frac{P(B | A)P(A)}{P(B | A)P(A) + P(\overline B | A)P(A)} 
      $$
   </p>

   <p>
      Remember that we called $P(x)$ the <em>prior</em> probability. The prior is the 
      probability distribution that represents your uncertainty over the random variable
      X. The <em>posterior</em> is the distribution representing your uncertainty after
      you have observed events that are related to or influence your event-of-interest: It is 
      a conditional distribution, conditioning on the observed data. Bayes' theorem has
      given us a way to relate the two.
   </p>
   <p>
      <img src="##IMG_DIR##/bayes_rule_flow_chart.PNG" 
           alt="Flow diagram of Bayes Rule converting prior probability to posterior">
   </p>


  
      <h4>Alternative Statement</h4>
      <p>
         This can sometimes be usefull re-stated as follows. If all events $E_i$ are 
         mutually exclusive and exhaustive and we have some other event A then we can
         write:

         $$
            P(E_i | A) = \frac{P(A | E_i)P(E_i)}{P(A)}
         $$

         And because in this case,
      
         $$
         \begin{align}
            P(A) &= P(A \cap E_1) + P(A \cap E_2) + \cdots + P(A \cap E_n) \\
                 &= P(A | E_1)P(E_1) + P(A | E_2)P(E_2) + \cdots + P(A | E_n)P(E_n)
         \end{align}
         $$

         We can say:
   
         $$
            P(E_i | A) = \frac{P(A | E_i)P(E_i)}{P(A | E_1)P(E_1) + P(A | E_2)P(E_2) + \cdots + P(A | E_n)P(E_n)}
         $$
   
         The advantage of this expression is that the probabilities involves are sometimes
         more readily available.
      </p>

<h2>Discrete Probability Distributions</h2>
<div>
   <h3>General Definitions</h3>
   <p>
      The <b>Probability Mass Function (PMF)</b> is another name for the <b>Probability
      Distribution Function (PDF)</b>, $P(x)$, of a discrete random variable X 
      expresses the probability that $X$ takes the value $x$. I.e,

      $$
      P(x) \equiv P(X = x), \ \  \forall x
      $$

      The PMF has the following properties:

      $$
      0 \le P(x) \le 1\, \  \forall x\\
      \sum_x P(x) = 1
      $$
   </p>
   <p>
      The <b>Cumulative Mass Function (CMF)</b> or <b>Cumulative Probability Function (CPF)</b>,
      $F(x_0)$, for a random variable $X$,
      gives the probability that X does not exceed the value $x_0$:
   
      $$ F(x_0) = P(X \le x_0) = \sum_{x \le x_0} P(x)$$

      The CMF has the following properties:

      $$
      0 \le F(X_0) \le 1, \ \ \forall x_0\\
      x_0 \lt x_1 \implies F(x_0) \lt F(x_1)
      $$
   </p>
   <h3>Expected Value and Variance</h3>
   <p>
      <b>Expected value</b> defined as:

      $$
      E(X) = \mu = \sum_x xP(x)
      $$

      Where $\mu$ is called the <b>mean</b> and is the mean of the <b>population</b>.
   </p>
   <p>
      <b>Variance</b>, $\sigma^2$ is the average squared distance from the mean and is 
      defined as follows. The square is taken so that distances don't cancel 
      eachother out (i.e, a negative distance and positive distance could 
      result is a very small average distance, which is not what we want).

      $$
      \begin{align}
         \sigma^2 &= \sum_x (x - \mu)^2P(x) &= E[(X - \mu)^2] \\
                  &= \sum_x x^2P(x) - \mu^2 &= E(X^2) - \mu^2
      \end{align}
      $$

      <b>Standard Deviation</b>, $\sigma$, is the positive square root of
      the variance.
   </p>
   <p>
      For example, lets say that we have weighted dice so that the
      probabilities are as follows:
   </p>
   <table class="allborders">
      <tr><td>Value</td><td>Probability</td></tr>
      <tr><td>1</td><td>0.05</td></tr>
      <tr><td>2</td><td>0.1</td></tr>
      <tr><td>3</td><td>0.1</td></tr>
      <tr><td>4</td><td>0.1</td></tr>
      <tr><td>5</td><td>0.1</td></tr>
      <tr><td>6</td><td>0.55</td></tr>
   </table>
   <p>
      The population mean, $\mu$ becomes:
      $$
      E[X] = \mu = \sum_x xP(x) = 1\times 0.05 + 0.1 \times 2 + 0.1 \times 3 + 0.1 \times 4 + 0.1 \times 5 + 0.55 \times 6 = 4.75
      $$

      Of course, the dice does not have a face value of 4.75, but over many many rolls this would be the average score.
      The variance and standard deviation are calculated in the same way using the above formulas.
   </p>
   <h4>Linear Functions Of X</h4>
   <p>
      The expected value and variance of a linear function of $X$ is another farily useful result.
      For example, we could arbitrarily define a function over dice rolls. Not sure why we'd do this,
      but say we said the experiement result was $g(X) = 2X + 5$ where $X$ is the random variable which gives
      the dice face rolled. Now we have:
   </p>
   <table class="allborders">
      <tr><td>g(x)</td><td>Probability</td></tr>
      <tr><td>7</td><td>0.05</td></tr>
      <tr><td>9</td><td>0.1</td></tr>
      <tr><td>11</td><td>0.1</td></tr>
      <tr><td>13</td><td>0.1</td></tr>
      <tr><td>15</td><td>0.1</td></tr>
      <tr><td>17</td><td>0.55</td></tr>
   </table>
   <p>
      The expected value of $g(x)$ is therefore:
      $$
      E[g(X)] = \mu = \sum_x xP(x) = 7 \times 0.05 + 0.1 \times 9 + 0.1 \times 11 + 0.1 \times 13 + 0.1 \times 15 + 0.55 \times 17 = 14.5
      $$

      Interestingly $14.5 = 2 \times 4.75 + 5$! It looks like $E[g(X)] = g(\mu_x)$, and
      for <em>linear</em> functions this is the case (but not so if $g(X)$ is not linear!).
      When $g(X)$ is <b>LINEAR</b> and $g(X) = a + bX$:

      $$
      \begin{align}
      \mu_{g(X)} &= E[a + bX] \\
                 &= a + b\mu_X \\
                 \\
      \sigma_{g(X)}^2 &= var[a + bX] \\
                      &= b^2\sigma_X^2
      \end{align}
      $$
   </p>

   <h3>Binomial Distribution</h3>
   <h4>Bernoulli Model</h4>
   <p>
      Experiment with two mutually exclusive and exhaustive outcomes. One has
      the probability $p$ and the other has probability $(1-p)$.

      $$
         \begin{align}
         P(0) &= P(fail)\\
              &= (1-p) \\
              \\
         P(1) &= P(success) \\
         &= p
         \end{align}
      $$

      Therefore, using the formulas for mean and variance from the previous
      sections, we can say the following.

      $$
      \begin{align}
         \mu_x &= E[X] \\
         &= \sum_x xP(x) \\
         &= (0)(1-p) + (1)p \\
         &= p\\
         \\
         \sigma_x^2 &= E[(X-\mu)^2] \\
         &= \sum(x - \mu_x)^2P(x) \\
         &= p(1-p)
      \end{align}
      $$
   </p>
   <h4>Binomial Distribution</h4>
   <p>
      Bernoulli experiment repeated $n$ times where the repetitions are
      <b>independent</b>. This is like selection <b>with replacement</b>.
   </p>

   <p>
      We know from previous discussions that if two events are independent
      then $P(A \cap B) = P(A)P(B)$ and by extension that $P(A \cap B \cap \dots \cap Z) = P(A)P(B) \dots P(Z)$.
      Therefore if I do $n$ experiments and want to know the probablity of $m$
      successes <em>in a row</em> and then $n-m$ failures <em>in a row</em>, the probability is:

      $$
      \begin{align}
         P(m\ successes) &= P(1)P(1)\dots P(1)P(0)P(0)\dots P(0) \\
         &= p^m(1-p)^{n-m}
      \end{align}
      $$

      Where there are $m$ $P(1)$'s in the above equation and $(n-m)$ $P(0)$'s. BUT
      this would be the probability of getting $m$ successes <em>in a row</em> and then
      $(n-m)$ failures in a row. The question, however, doesn't care about the specific order:
      we dont care if we get SSFF.. or SFSF... or SSFS... and so on. We need to figure
      out how many of these combinations there are and account for this!
   </p>
   <p>
      Let's take a simple example. I have a bag with 5 balls in it: 3 blue, 2 red.
      What is the probability of drawing 1 blue ball and 1 red ball if I select
      using replacement (to make the selections independent). Replacement means
      that what ever ball I pick first, I record the result and then put it
      back in the bag before making my next pick. In this way, the probability
      of selecting a particular colour <em>does NOT change</em> per pick.
   </p>
   <p>
      Note that there are only 2 colours of ball in our bag... this is because
      we are talking about an experiement where there are only two outcomes, 
      labeled &quot;success&quot; and &quot;failure&quot;. We could view
      selecting a blue as &quot;success&quot; and a red as &quot;failure&quot;,
      or vice versa.
   </p>
   <p>
      So... selecting a blue and a red ball. Sounds like $P(blue \cap red)$ right?
      Well, almost, but <em>not quite</em>. Take a look at the sample space below, 
      out of which, the events of interested are highlighted in a light blue colour.
   </p>
   <p>
      Here I am using an alphabetical subscript to indicate the specific ball. I.e.
      $B_x$ is a different ball to $B_y$. The order of selection is given by the
      order of writing. I.e., &quot;$B_x\ B_y$&quot; means $B_x$ was picked on the first turn and then
      $B_y$ was picked on the second turn.
   </p>
   <table class="allborders">
      <tr><td>...</td>
          <td>$B_x$</td>
          <td>$B_y$</td>
          <td>$B_z$</td>
          <td>$R_x$</td>
          <td>$R_y$</td></tr>
      <tr><td>$B_x$</td> 
          <td>$B_x B_x$</td>
          <td>$B_x B_y$</td>
          <td>$B_x B_z$</td>
          <td class="selcell">$B_x R_x$</td>
          <td class="selcell">$B_x R_y$</td></tr>
      <tr><td>$B_y$</td> 
          <td>$B_y B_x$</td>
          <td>$B_y B_y$</td>
          <td>$B_y B_z$</td>
          <td class="selcell">$B_y R_x$</td>
          <td class="selcell">$B_y R_y$</td></tr>
      <tr><td>$B_z$</td> 
          <td>$B_z B_x$</td>
          <td>$B_z B_y$</td>
          <td>$B_z B_z$</td>
          <td class="selcell">$B_z R_x$</td>
          <td class="selcell">$B_z R_y$</td></tr>
      <tr><td>$R_x$</td> 
          <td class="selcell">$R_x B_x$</td>
          <td class="selcell">$R_x B_y$</td>
          <td class="selcell">$R_x B_z$</td>
          <td>$R_x R_x$</td>
          <td>$R_x R_y$</td></tr>
      <tr><td>$R_y$</td> 
          <td class="selcell">$R_y B_x$</td>
          <td class="selcell">$R_y B_y$</td>
          <td class="selcell">$R_y B_z$</td>
          <td>$R_y R_x$</td>
          <td>$R_y R_y$</td></tr>
   </table>
   <p>
      There are two clear groups of outcomes that will satisfy the question.
      We see that in one group we drew a red ball first and in the other we
      drew a blue ball first. So, there are $5 \times 5$ total possible
      events, and of these $6 + 6$ are of interest. Therefore,

      $$
      \begin{align}
         P(drawing\ a\ blue\ and\ a\ red) &= \frac{6}{25} + \frac{6}{25} \\
         &= 2 \times \frac{6}{25}
      \end{align}
      $$

      But, hang on  minute! Isn't $P(drawing\ a\ blue\ and\ a\ red)$ the same
      as $P(B \cap R)$?! Well, no, as we can see below...

      $$
         P(B \cap R) = P(B) \times P(R) = \frac{3}{5} \times \frac{2}{5} = \frac{6}{25}
      $$

      So the two expressions are clearly not the same thing. To clear up my
      confusion I asked the guys at Maths Exchange, and got the following
      <a href="http://math.stackexchange.com/questions/1705507/binomial-distribution-p-mboxblue-cap-mboxred-ne-p-mboxpick-a-blue-a"
         target="_blank">awesome answer</a> from a very nice chap named 
      <a href="http://math.stackexchange.com/users/6622/joriki" target="_blank">Joriki</a>.
      Im quoting it (almost) verbatim because it was just so good!
   </p>
   <div style="border-left: 3px solid lightblue; padding-left: 10px;">
      <p>This confusion can be resolved by careful attention to definitions and notation.
      </p>
      <p>Where you write $P(B\cap R)$, you call the events $B$ and $R$ 
         &quot;a blue&quot; and &quot;a red&quot; respectively. Implicitly 
         you're referring to two different draws (if you were referring to a 
         single draw, you'd have $P(B\cap R)=0$), but you're not 
         distinguishing the events accordingly, and this leads to confusion.
      </p>
      <p>
         The events you are interested are $B_1$, a blue ball is drawn on 
         the first draw, $R_1$, a red ball is drawn on the first draw, 
         $B_2$, a blue ball is drawn on the second draw, and $R_2$, a red 
         ball is drawn on the second draw. We have $P(B_1)=P(B_2)=\frac35$ 
         and $P(R_1)=P(R_2)=\frac25$.
      </p>
      <p>You want to know $P((B_1\cap R_2)\cup(B_2\cap R_1))$. Since the 
         events $B_1\cap R_2$ and $B_2\cap R_1$ are mutually exclusive, this is

         $$P((B_1\cap R_2)\cup(B_2\cap R_1))=P(B_1\cap R_2)+P(B_2\cap R_1)\;,$$

         and since the first and second draws are independent, this is 

         $$
         \begin{align}
         P(B_1\cap R_2)+P(B_2\cap R_1) &= P(B_1)P(R_2)+P(B_2)P(R_1) \\
         &= 2\cdot\frac35\cdot\frac25 \\
         &= 2\cdot P(B)P(R) \\
         &= 2\cdot p^1\cdot (1-p)^1 
         \end{align}
         $$
      </p>
   </div>
   <p>
      Note, that in Jorki's example $R_1$ and $R_2$ do <em>not</em> refer to different
      balls: the subscripts refer to different <em>draws</em>. Therefore, $R_1$ and $R_2$
      could be the same red ball drawn on turn $1$ and turn $2$.
   </p>
   <p>
      So, having understood this, we can see that to get the total probability
      of $m$ successess (1 blue ball) out of $n$ trials (2 selections), in 
      the case where events are
      independent, we are concerned with the number of 
      <a href="math_revision.html#combinations_permutations">combintations</a> in
      which the events can occur.
   </p>
   <p>
      The formula for the binomial distribution is...

      $$
      \begin{align}
      P(m\ successes\ in\ n\ independent\ trials) &= P(m) \\
      &={_{n}C_m} \cdot p^m \cdot (1-p)^{(n-m)}\\
      &= \frac{n!}{m!(n-m)!} \cdot p^m \cdot (1-p)^{(n-m)}
      \end{align}
      $$

      For $m = 0, 1, \dots, n$.
   </p>
   <p>
      This, incidentally is the same as asking for $P((n-m)\ failures\ in\ n\ independent\ trials)$ because

      $$
      \begin{align}
      {_{n}C_{(n-m)}} &= \frac{n!}{(n-(n-m))!(n-m)!}\\
      &= \frac{n!}{m!(n-m)!}\\
      &= {_{n}C_m}
      \end{align}
      $$
   </p>
   <p>
      Let's do this to exhaustion... let's imagine another bag. It doesn't 
      matter how many blue and red balls are in there, just so long as I can
      select 3 blue balls and 1 red. $P(blue) = p$ and $P(red) = (1-p)$.
      Once we've made this selection of 3 blues, 1 red, the question is,
      how many ways were there of getting to this outcome. Now let's check 
      our understanding of using combinations (esp. vs. permutations) to get this...
   </p>
   <p>
      We can draw a little outcome tree as follows:
   </p>
   <p>
   <img src="##IMG_DIR##/bayes_bbbr_decision_tree.png"/>
   </p>
   <p>
      Clearly there are 4 ways to arrive at the selection of 3 blues and 1 red,
      once we have made that particular selection. Remember we're not asking
      for a blue/red on a specific turn... we just care about the final
      outcome, irrespective of the order in which the balls were picked.
      And we can see...

      $$
      \begin{align}
      {_4C_3} &= \frac{4!}{3!(4-3)!}
      &= 4
      \end{align}
      $$
   </p>
   <p>
      Why don't we use permutations? The answer is that we don't care if we got
      $B_aB_bB_cR_a$ or $B_bB_aB_cR_a$ or $B_cR_aB_aB_b$ etc etc, where, as before,
      the alphabetical substrcipts distinguish the ball, not the turn on which
      it is drawn as that is given by order of writing.
   </p>
   <p>
      Having gone through this we can then use the formulas for expected value,
      or mean, and variance. To make the notation similar to previous examples
      where we used $P(x)$, in the above formula I just change $m$ for $x$ so
      that we get

      $$
      P(x)= \frac{n!}{x!(n-x)!} \cdot p^x \cdot (1-p)^{(n-x)}
      $$

      Where $x = 0, 1, \dots, n$, meanding that this is the probability of 
      $x$ successes out of $n$ trials.
   </p>
   <p>
      Recalling that 
      $$
      E(X) = \mu = \sum_x xP(x)
      $$

      We can say that the population mean for the Bernoulli distribution
      is

      $$
      \begin{align}
      E(X) = \mu &= \sum_{x=0}^{x\le n} x \cdot \left(\frac{n!}{x!(n-x)!} \cdot p^x \cdot (1-p)^{(n-x)}\right) 
      \end{align}
      $$
      
      And... the rest of the proof gets a little complicated... 
      <a href="http://www.math.ubc.ca/~feldman/m302/binomial.pdf"
         target="_blank">this PDF by some giy called Joel Feldman gives the derivation</a>.
   </p>
   <p>
      The population <b>mean</b> and <b>variance</b> are summarised as follows.
      $$
         \begin{align}
            \mu &= E[X] \\
                &= nP\\
                \\
            \sigma_x^2 &= E[(X - \mu)^2] \\
            &= nP(1-P)
         \end{align}
      $$
   </p>
   <p>
      Often when talking about a binomial distribution you will see something like

      $$
      P(X | n = ?, p = ?)
      $$

      This is the binomial distribution for $X$ successes out of $n$ trials
      with the probability of success given by $p$.

   </p>
   <p>
      We can plot some example distributions... lets do this using Python.
   </p>
   <pre  class="prettyprint linenums">import matplotlib.pyplot as pl
import numpy as np
from matplotlib.font_manager import FontProperties
from scipy.stats import binom

fontP = FontProperties()
fontP.set_size('small')

n=50
pLst=[0.1, 0.25, 0.5, 0.75, 0.9]
x = np.arange(-1, n+2)
fig, ax = pl.subplots()

for p in pLst:
   dist = binom(n, p)
   ax.plot(x, dist.pmf(x),linestyle='steps-mid')

ax.legend(['$p={}$'.format(p) for p in pLst], 
          ncol = 3, 
          prop=fontP, 
          bbox_to_anchor=[0.5, 1.0], 
          loc='upper center')
fig.show()
fig.savefig('binomial_distrib.png', format='png')</pre>
   <p>
      <img src="##IMG_DIR##/binomial_distrib_example.png"/>
   </p>


   <h3>Poisson Distribution</h3>
   <p>
      Didn't like the starting explanation in [1] so had a look on Wikipedia and
      found a link to the 
      <a href="http://www.umass.edu/wsp/resources/poisson/index.html"
         target="_blank">UMass Amherst Uni's stats page on the Poisson distribution</a>
      which I though was really well written. That is the main reference here.
   </p>
   <p>
      Poisson distribution gives the probability of an event occuring some
      number of times in a <em>specific interval</em>. This could be time, distance, 
      whatever. What matters is that the <em>interval is specific and fixed</em>. 
     <p>
   <p>The example used 
      on the UMass Amherst is letters received in a day. The interval here is
      one day. The poisson distribution will then tell you the probability of
      getting a certain number of letters in one day, the <em>interval</em>. Other
      examples could include the number of planes landing at an airport in a day
      or the number of linux server crashes in a year etc...
   </p>
   <p>
      The interval is one component. The other is an already observed average
      rate per interval, or expected number of successes in an interval, $\lambda$. 
      For example, we might have observed we get on average 5 
      letters per day ($\lambda=5$), or that 1003 planes land at our airport 
      ($\lambda=1003$) per day or that there are 4 linux server crashes per year 
      ($\lambda=4$) etc...
   </p>
   <p>
      So, poisson has an <em>interval</em> and an observed <em>average count</em>
      for that interval. The following assumptions are made:
   </p>
   <ul>
      <li>The #occurrences can be counted as an integer</li>
      <li>The average #occurrences is known</li>
      <li>The probability of the occurence of an event is constant for all 
          subintervals. E.g., if we divided the day into minutes, the probability
          of receiving a letter in any minute of the day is the same as for any
          other minute.</li>
      <li>There can be no more than one occurrence in the subinterval</li>
      <li>Occurrences are independent</li>
   </ul>
   <p>
      The distribution is defined as follows, where $\lambda$ is the expected 
      number of events per interval.

      $$
      P(X = x) = \frac{e^{-\lambda}\lambda^x}{x!},\ \ x \ge 0
      $$
   </p>
   <p>
      Eek... didn't like the look of trying to derive the mean and variance.
      The population <b>mean</b> and <b>variance</b> are as follows.

      $$
      \begin{align}
      \mu_x &= E(X) = \lambda\\
      \\
      \sigma^2_x &= E[(X-\mu_x)^2] = \lambda
      \end{align}
      $$
   </p>
   <p>
      We can plot some example distributions... lets do this using Python.
   </p>

   <pre  class="prettyprint linenums">import matplotlib.pyplot as pl
import numpy as np
from matplotlib.font_manager import FontProperties
from scipy.stats import poisson

fontP = FontProperties()
fontP.set_size('small')

expectedNumberOfSuccessesLst = [1, 5, 10, 15]
x = np.arange(-1, 31)
fig, ax = pl.subplots()

for numSuccesses in expectedNumberOfSuccessesLst:
   ax.plot(x, poisson.pmf(x, numSuccesses),linestyle='steps-mid')

ax.legend(['$\lambda={}$'.format(n) for n in expectedNumberOfSuccessesLst], 
          ncol = 3, 
          prop=fontP, 
          bbox_to_anchor=[0.5, 1.0], 
          loc='upper center')
fig.show()
pl.show()
fig.savefig('poisson_distrib.png', format='png')</pre>
   <p>
      <img src="##IMG_DIR##/poisson_distrib.png"/>
   </p>

</div>

   
</div>

</body>
</html>
